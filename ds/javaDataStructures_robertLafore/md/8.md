8
=

Binary Trees
------------

> In this chapter we switch from algorithms, the focus of Chapter 7,
> "Advanced Sorting," to data structures. Binary trees are one of the
> fundamental data storage structures
>
> used in programming. They provide advantages that the data structures
> we've seen so far cannot. In this chapter we'll learn why you would
> want to use trees, how they work, and how to go about creating them.

#### Why Use Binary Trees?

> Why might you want to use a tree? Usually, because it combines the
> advantages of two other structures: an ordered array and a linked
> list. You can search a tree quickly, as you can an ordered array, and
> you can also insert and delete items quickly, as you can with a linked
> list. Let's explore these topics a bit before delving into the details
> of trees.

##### Slow Insertion in an Ordered Array

> Imagine an array in which all the elements are arranged in
> order---that is, an ordered array, such as we saw in Chapter 2,
> "Arrays." As we learned, you can quickly search such an array for a
> particular value, using a binary search. You check in the center of
> the array; if the object you're looking for is greater than what you
> find there, you narrow your search to the top half of the array; if
> it's less, you narrow your search to the bottom half. Applying this
> process repeatedly finds the object in O(logN) time. You can also
> quickly iterate through an ordered array, visiting each object in
> sorted order.
>
> On the other hand, if you want to insert a new object into an ordered
> array, you first need to find where the object will go, and then move
> all the objects with greater keys up

##### IN THIS CHAPTER

-   Why Use Binary Trees?

-   Tree Terminology

-   An Analogy

-   How Do Binary Search Trees Work?

-   Finding a Node

-   Inserting a Node

-   Traversing the Tree

-   Finding Maximum and Minimum Values

-   Deleting a Node

-   The Efficiency of Binary Trees

-   Trees Represented as Arrays

-   Duplicate Keys

-   The Complete tree.java

> Program

-   The Huffman Code

> 366 **CHAPTER 8** Binary Trees
>
> one space in the array to make room for it. These multiple moves are
> time-consum- ing, requiring, on the average, moving half the items
> (N/2 moves). Deletion involves the same multimove operation and is
> thus equally slow.
>
> If you're going to be doing a lot of insertions and deletions, an
> ordered array is a bad choice.

##### Slow Searching in a Linked List

> On the other hand, as we saw in Chapter 5, "Linked Lists," insertions
> and deletions are quick to perform on a linked list. They are
> accomplished simply by changing a few references. These operations
> require O(1) time (the fastest Big O time).
>
> Unfortunately, however, *finding* a specified element in a linked list
> is not so easy. You must start at the beginning of the list and visit
> each element until you find the one you're looking for. Thus, you will
> need to visit an average of N/2 objects, comparing each one's key with
> the desired value. This process is slow, requiring O(N) time. (Notice
> that times considered fast for a sort are slow for data structure
> operations.)
>
> You might think you could speed things up by using an ordered linked
> list, in which the elements were arranged in order, but this doesn't
> help. You still must start at the beginning and visit the elements in
> order, because there's no way to access a given element without
> following the chain of references to it. (Of course, in an ordered
> list it's much quicker to visit the nodes in order than it is in a
> non-ordered list, but that doesn't help to find an arbitrary object.)

##### Trees to the Rescue

> It would be nice if there were a data structure with the quick
> insertion and deletion of a linked list, and also the quick searching
> of an ordered array. Trees provide both these characteristics, and are
> also one of the most interesting data structures.

##### What Is a Tree?

> We'll be mostly interested in a particular kind of tree called a
> *binary tree*, but let's start by discussing trees in general before
> moving on to the specifics of binary trees.
>
> A tree consists of *nodes* connected by *edges*. Figure 8.1 shows a
> tree. In such a picture of a tree (or in our Workshop applet) the
> nodes are represented as circles, and the edges as lines connecting
> the circles.
>
> Trees have been studied extensively as abstract mathematical entities,
> so there's a large amount of theoretical knowledge about them. A tree
> is actually an instance of a more general category called a *graph*,
> but we don't need to worry about that here.
>
> We'll discuss graphs in Chapter 13, "Graphs," and Chapter 14,
> "Weighted Graphs."

Tree Terminology 367

> Nodes
>
> ![](media/image1.png)
>
> ***FIGURE 8.1*** A general (non-binary) tree.
>
> In computer programs, nodes often represent such entities as people,
> car parts, airline reservations, and so on---in other words, the
> typical items we store in any kind of data structure. In an OOP
> language like Java these real-world entities are represented by
> objects.
>
> The lines (edges) between the nodes represent the way the nodes are
> related. Roughly speaking, the lines represent convenience: It's easy
> (and fast) for a program to get from one node to another if there is a
> line connecting them. In fact, the *only* way to get from node to node
> is to follow a path along the lines. Generally, you are restricted to
> going in one direction along edges: from the root downward.
>
> Edges are likely to be represented in a program by references, if the
> program is written in Java (or by pointers if the program is written
> in C or C++).
>
> Typically, there is one node in the top row of a tree, with lines
> connecting to more nodes on the second row, even more on the third,
> and so on. Thus, trees are small on the top and large on the bottom.
> This may seem upside-down compared with real trees, but generally a
> program starts an operation at the small end of the tree, and it's
> (arguably) more natural to think about going from top to bottom, as in
> reading text.
>
> There are different kinds of trees. The tree shown in Figure 8.1 has
> more than two children per node. (We'll see what "children" means in a
> moment.) However, in this chapter we'll be discussing a specialized
> form of tree called a *binary tree*. Each node in a binary tree has a
> maximum of two children. More general trees, in which nodes can have
> more than two children, are called multiway trees. We'll see an
> example in Chapter 10, "2-3-4 Trees and External Storage."

#### Tree Terminology

> Many terms are used to describe particular aspects of trees. You need
> to know a few of them so our discussion will be comprehensible.
> Fortunately, most of these terms are related to real-world trees or to
> family relationships (as in parents and children),
>
> 368 **CHAPTER 8** Binary Trees
>
> so they're not hard to remember. Figure 8.2 shows many of these terms
> applied to a binary tree.

![](media/image9.png)Root

A

> B is the
>
> The dashed line is a path
>
> Level 0
>
> D is the left child of B
>
> parent of D
>
> B and E C
>
> E is the right child of B

A.  E F G

> Level 1
>
> Level 2
>
> H A subtree [ ]{.underline} I J

with F as

its root

> Level 3
>
> H, E, I, J, and G are leaf nodes
>
> ***FIGURE 8.2*** Tree terms.

##### Path

> Think of someone walking from node to node along the edges that
> connect them. The resulting sequence of nodes is called a *path*.

##### Root

> The node at the top of the tree is called the *root*. There is only
> one root in a tree. For a collection of nodes and edges to be defined
> as a tree, there must be one (and only one!) path from the root to any
> other node. Figure 8.3 shows a non-tree. You can see that it violates
> this rule.

![](media/image20.png)

> ***FIGURE 8.3*** A non-tree.

Tree Terminology 369

##### Parent

> Any node (except the root) has exactly one edge running upward to
> another node. The node above it is called the *parent* of the node.

##### Child

> Any node may have one or more lines running downward to other nodes.
> These nodes below a given node are called its *children*.

##### Leaf

> A node that has no children is called a *leaf node* or simply a
> *leaf*. There can be only one root in a tree, but there can be many
> leaves.

##### Subtree

> Any node may be considered to be the root of a *subtree*, which
> consists of its chil- dren, and its children's children, and so on. If
> you think in terms of families, a node's subtree contains all its
> descendants.

##### Visiting

> A node is *visited* when program control arrives at the node, usually
> for the purpose of carrying out some operation on the node, such as
> checking the value of one of its data fields or displaying it. Merely
> passing over a node on the path from one node to another is not
> considered to be visiting the node.

##### Traversing

> To *traverse* a tree means to visit all the nodes in some specified
> order. For example, you might visit all the nodes in order of
> ascending key value. There are other ways to traverse a tree, as we'll
> see later.

##### Levels

> The *level* of a particular node refers to how many generations the
> node is from the root. If we assume the root is Level 0, then its
> children will be Level 1, its grandchil- dren will be Level 2, and so
> on.

##### Keys

> We've seen that one data field in an object is usually designated a
> *key value*. This value is used to search for the item or perform
> other operations on it. In tree diagrams, when a circle represents a
> node holding a data item, the key value of the item is typically shown
> in the circle. (We'll see many figures later on that show nodes
> containing keys.)
>
> 370 **CHAPTER 8** Binary Trees

##### Binary Trees

> If every node in a tree can have at most two children, the tree is
> called a *binary tree*. In this chapter we'll focus on binary trees
> because they are the simplest and the most common.
>
> The two children of each node in a binary tree are called the *left
> child* and the *right child*, corresponding to their positions when
> you draw a picture of a tree, as shown in Figure 8.2. A node in a
> binary tree doesn't necessarily have the maximum of two children; it
> may have only a left child, or only a right child, or it can have no
> chil- dren at all (in which case it's a leaf).
>
> The kind of binary tree we'll be dealing with in this discussion is
> technically called a
>
> *binary search tree*. Figure 8.4 shows a binary search tree.

![](media/image26.png)

> ***FIGURE 8.4*** A binary search tree.
>
> **[NOTE ]{.underline}**
>
> The defining characteristic of a binary search tree is this: A node's
> left child must have a key less than its parent, and a node's right
> child must have a key greater than or equal to its parent.

#### An Analogy

> One commonly encountered tree is the hierarchical file structure in a
> computer system. The root directory of a given device (designated with
> the backslash, as in C:\\, on many systems) is the tree's root. The
> directories one level below the root directory are its children. There
> may be many levels of subdirectories. Files represent leaves; they
> have no children of their own.
>
> How Do Binary Search Trees Work? 371
>
> Clearly, a hierarchical file structure is not a binary tree, because a
> directory may have many children. A complete pathname, such as
> C:\\SALES\\EAST\\NOVEMBER\\SMITH.DAT, corresponds to the path from the
> root to the SMITH.DAT leaf. Terms used for the file structure, such as
> *root* and *path*, were borrowed from tree theory.
>
> A hierarchical file structure differs in a significant way from the
> trees we'll be discussing here. In the file structure, subdirectories
> contain no data; they contain only references to other subdirectories
> or to files. Only files contain data. In a tree, every node contains
> data (a personnel record, car-part specifications, or whatever). In
> addition to the data, all nodes except leaves contain references to
> other nodes.

#### How Do Binary Search Trees Work?

> Let's see how to carry out the common binary tree operations of
> finding a node with a given key, inserting a new node, traversing the
> tree, and deleting a node. For each of these operations we'll first
> show how to use the Binary Tree Workshop applet to carry it out; then
> we'll look at the corresponding Java code.

##### The Binary Tree Workshop Applet

> Start up the Binary Tree Workshop applet. You'll see a screen
> something like that shown in Figure 8.5. However, because the tree in
> the Workshop applet is randomly generated, it won't look exactly the
> same as the tree in the figure.

![](media/image36.png){width="2.7864873140857394in"
height="2.2866655730533685in"}

> ***FIGURE 8.5*** The Binary Tree Workshop applet.
>
> 372 **CHAPTER 8** Binary Trees

####### Using the Workshop Applet

> The key values shown in the nodes range from 0 to 99. Of course, in a
> real tree, there would probably be a larger range of key values. For
> example, if employees' Social Security numbers were used for key
> values, they would range up to 999,999,999.
>
> Another difference between the Workshop applet and a real tree is that
> the Workshop applet is limited to a depth of five; that is, there can
> be no more than five levels from the root to the bottom. This
> restriction ensures that all the nodes in the tree will be visible on
> the screen. In a real tree the number of levels is unlimited (until
> you run out of memory).
>
> Using the Workshop applet, you can create a new tree whenever you
> want. To do this, click the Fill button. A prompt will ask you to
> enter the number of nodes in the tree. This can vary from 1 to 31, but
> 15 will give you a representative tree. After typing in the number,
> press Fill twice more to generate the new tree. You can experiment by
> creating trees with different numbers of nodes.

####### Unbalanced Trees

> Notice that some of the trees you generate are *unbalanced*; that is,
> they have most of their nodes on one side of the root or the other, as
> shown in Figure 8.6. Individual subtrees may also be unbalanced.

![](media/image37.png)

> ***FIGURE 8.6*** An unbalanced tree (with an unbalanced subtree).
>
> How Do Binary Search Trees Work? 373
>
> Trees become unbalanced because of the order in which the data items
> are inserted. If these key values are inserted randomly, the tree will
> be more or less balanced.
>
> However, if an ascending sequence (like 11, 18, 33, 42, 65, and so on)
> or a descend- ing sequence is generated, all the values will be right
> children (if ascending) or left children (if descending) and the tree
> will be unbalanced. The key values in the Workshop applet are
> generated randomly, but of course some short ascending or descending
> sequences will be created anyway, which will lead to local imbalances.
> When you learn how to insert items into the tree in the Workshop
> applet, you can try building up a tree by inserting such an ordered
> sequence of items and see what happens.
>
> If you ask for a large number of nodes when you use Fill to create a
> tree, you may not get as many nodes as you requested. Depending on how
> unbalanced the tree becomes, some branches may not be able to hold a
> full number of nodes. This is because the depth of the applet's tree
> is limited to five; the problem would not arise in a real tree.
>
> If a tree is created by data items whose key values arrive in random
> order, the problem of unbalanced trees may not be too much of a
> problem for larger trees because the chances of a long run of numbers
> in sequence is small. But key values can arrive in strict sequence;
> for example, when a data-entry person arranges a stack of personnel
> files into order of ascending employee number before entering the
> data. When this happens, tree efficiency can be seriously degraded.
> We'll discuss unbal- anced trees and what to do about them in Chapter
> 9, "Red-Black Trees."

##### Representing the Tree in Java Code

> Let's see how we might implement a binary tree in Java. As with other
> data struc- tures, there are several approaches to representing a tree
> in the computer's memory. The most common is to store the nodes at
> unrelated locations in memory, and connect them using references in
> each node that point to its children.
>
> You can also represent a tree in memory as an array, with nodes in
> specific positions stored in corresponding positions in the array.
> We'll return to this possibility at the end of this chapter. For our
> sample Java code we'll use the approach of connecting the nodes using
> references.
>
> **[NOTE ]{.underline}**
>
> As we discuss individual operations, we'll show code fragments
> pertaining to that operation. The complete program from which these
> fragments are extracted can be seen toward the end of this chapter in
> Listing 8.1.
>
> 374 **CHAPTER 8** Binary Trees
>
> **The** Node **Class**
>
> First, we need a class of node objects. These objects contain the data
> representing the objects being stored (employees in an employee
> database, for example) and also references to each of the node's two
> children. Here's how that looks:
>
> class Node
>
> {
>
> int iData; // data used as key value
>
> double fData; // other data
>
> node leftChild; // this node's left child
>
> node rightChild; // this node's right child
>
> public void displayNode()
>
> {
>
> // (see Listing 8.1 for method body)
>
> }
>
> }
>
> Some programmers also include a reference to the node's parent. This
> simplifies some operations but complicates others, so we don't include
> it. We do include a method called displayNode() to display the node's
> data, but its code isn't relevant here.
>
> There are other approaches to designing class Node. Instead of placing
> the data items directly into the node, you could use a reference to an
> object representing the data item:
>
> class Node
>
> {
>
> person p1; // reference to person object
>
> node leftChild; // this node's left child
>
> node rightChild; // this node's right child
>
> }
>
> class person
>
> {
>
> int iData; double fData;
>
> }
>
> This approach makes it conceptually clearer that the node and the data
> item it holds aren't the same thing, but it results in somewhat more
> complicated code, so we'll stick to the first approach.
>
> How Do Binary Search Trees Work? 375
>
> **The** Tree **Class**
>
> We'll also need a class from which to instantiate the tree itself: the
> object that holds all the nodes. We'll call this class Tree. It has
> only one field: a Node variable that holds the root. It doesn't need
> fields for the other nodes because they are all accessed from the
> root.
>
> The Tree class has a number of methods. They are used for finding,
> inserting, and deleting nodes; for different kinds of traverses; and
> for displaying the tree. Here's a skeleton version:
>
> class Tree
>
> {
>
> private Node root; // the only data field in Tree
>
> public void find(int key)
>
> {
>
> }
>
> public void insert(int id, double dd)
>
> {
>
> }
>
> public void delete(int id)
>
> {
>
> }
>
> // various other methods
>
> } // end class Tree
>
> **The** TreeApp **Class**
>
> Finally, we need a way to perform operations on the tree. Here's how
> you might write a class with a main() routine to create a tree, insert
> three nodes into it, and then search for one of them. We'll call this
> class TreeApp:
>
> class TreeApp
>
> {
>
> public static void main(String\[\] args)
>
> {
>
> Tree theTree = new Tree; // make a tree
>
> theTree.insert(50, 1.5); // insert 3 nodes
>
> theTree.insert(25, 1.7);
>
> theTree.insert(75, 1.9);
>
> node found = theTree.find(25); // find node with key 25 if(found !=
> null)
>
> 376 **CHAPTER 8** Binary Trees
>
> System.out.println("Found the node with key 25"); else
>
> System.out.println("Could not find node with key 25");

} // end main()

} // end class TreeApp

> **[TIP ]{.underline}**
>
> In Listing 8.1 the main() routine also provides a primitive user
> interface so you can decide from the keyboard whether you want to
> insert, find, delete, or perform other operations.
>
> Next we'll look at individual tree operations: finding a node,
> inserting a node, traversing the tree, and deleting a node.

#### Finding a Node

> Finding a node with a specific key is the simplest of the major tree
> operations, so let's start with that.
>
> Remember that the nodes in a binary search tree correspond to objects
> containing information. They could be *person objects*, with an
> employee number as the key and also perhaps name, address, telephone
> number, salary, and other fields. Or they could represent car parts,
> with a part number as the key value and fields for quantity on hand,
> price, and so on. However, the only characteristics of each node that
> we can see in the Workshop applet are a number and a color. A node is
> created with these two characteristics, and keeps them throughout its
> life.

##### Using the Workshop Applet to Find a Node

> Look at the Workshop applet, and pick a node, preferably one near the
> bottom of the tree (as far from the root as possible). The number
> shown in this node is its *key value*. We're going to demonstrate how
> the Workshop applet finds the node, given the key value.
>
> For purposes of this discussion we'll assume you've decided to find
> the node repre- senting the item with key value 57, as shown in Figure
> 8.7. Of course, when you run the Workshop applet, you'll get a
> different tree and will need to pick a different key value.
>
> Click the Find button. The prompt will ask for the value of the node
> to find. Enter 57
>
> (or whatever the number is on the node you chose). Click Find twice
> more.

Finding a Node 377

![](media/image47.png)

> ***FIGURE 8.7*** Finding node 57.
>
> As the Workshop applet looks for the specified node, the prompt will
> display either Going to left child or Going to right child, and the
> red arrow will move down one level to the right or left.
>
> In Figure 8.7 the arrow starts at the root. The program compares the
> key value 57 with the value at the root, which is 63. The key is less,
> so the program knows the desired node must be on the left side of the
> tree---either the root's left child or one of this child's
> descendants. The left child of the root has the value 27, so the
> compari- son of 57 and 27 will show that the desired node is in the
> right subtree of 27. The arrow will go to 51, the root of this
> subtree. Here, 57 is again greater than the 51 node, so we go to the
> right, to 58, and then to the left, to 57. This time the compari- son
> shows 57 equals the node's key value, so we've found the node we want.
>
> The Workshop applet doesn't do anything with the node after finding
> it, except to display a message saying it has been found. A serious
> program would perform some operation on the found node, such as
> displaying its contents or changing one of its fields.

##### Java Code for Finding a Node

> Here's the code for the find() routine, which is a method of the Tree
> class:
>
> public Node find(int key) // find node with given key
>
> { // (assumes non-empty tree)
>
> Node current = root; // start at root
>
> 378 **CHAPTER 8** Binary Trees
>
> while(current.iData != key) // while no match,
>
> {
>
> if(key \< current.iData) // go left? current = current.leftChild;
>
> else
>
> current = current.rightChild; // or go right? if(current == null) //
> if no child,
>
> return null; // didn't find it
>
> }
>
> return current; // found it
>
> }
>
> This routine uses a variable current to hold the node it is currently
> examining. The argument key is the value to be found. The routine
> starts at the root. (It has to; this is the only node it can access
> directly.) That is, it sets current to the root.
>
> Then, in the while loop, it compares the value to be found, key, with
> the value of the iData field (the key field) in the current node. If
> key is less than this field, current is set to the node's left child.
> If key is greater than (or equal) to the node's iData field, current
> is set to the node's right child.

####### Can't Find the Node

> If current becomes equal to null, we couldn't find the next child node
> in the sequence; we've reached the end of the line without finding the
> node we were looking for, so it can't exist. We return null to
> indicate this fact.

####### Found the Node

> If the condition of the while loop is not satisfied, so that we exit
> from the bottom of the loop, the iData field of current is equal to
> key; that is, we've found the node we want. We return the node so that
> the routine that called find() can access any of the node's data.

##### Tree Efficiency

> As you can see, the time required to find a node depends on how many
> levels down it is situated. In the Workshop applet there can be up to
> 31 nodes, but no more than five levels---so you can find any node
> using a maximum of only five comparisons.
>
> This is O(logN) time, or more specifically O(log2N) time, the
> logarithm to the base 2. We'll discuss this further toward the end of
> this chapter.

#### Inserting a Node

> To insert a node, we must first find the place to insert it. This is
> much the same process as trying to find a node that turns out not to
> exist, as described in the "Can't

Inserting a Node 379

> Find the Node" section. We follow the path from the root to the
> appropriate node, which will be the parent of the new node. When this
> parent is found, the new node is connected as its left or right child,
> depending on whether the new node's key is less or greater than that
> of the parent.

##### Using the Workshop Applet to Insert a Node

> To insert a new node with the Workshop applet, press the Ins button.
> You'll be asked to type the key value of the node to be inserted.
> Let's assume we're going to insert a new node with the value 45. Type
> this number into the text field.
>
> The first step for the program in inserting a node is to find where it
> should be inserted. Figure 8.8a shows how this step looks.

![](media/image61.png)

a)  Before insertion b) After insertion

> ***FIGURE 8.8*** Inserting a node.
>
> The value 45 is less than 60 but greater than 40, so we arrive at node
> 50. Now we want to go left because 45 is less than 50, but 50 has no
> left child; its leftChild field is null. When it sees this null, the
> insertion routine has found the place to attach the new node. The
> Workshop applet does this by creating a new node with the value 45
> (and a randomly generated color) and connecting it as the left child
> of 50, as shown in Figure 8.8b.

##### Java Code for Inserting a Node

> The insert() function starts by creating the new node, using the data
> supplied as arguments.
>
> 380 **CHAPTER 8** Binary Trees
>
> Next, insert() must determine where to insert the new node. This is
> done using roughly the same code as finding a node, described in the
> section "Java Code for Finding a Node." The difference is that when
> you're simply trying to *find* a node and you encounter a null
> (non-existent) node, you know the node you're looking for doesn't
> exist so you return immediately. When you're trying to *insert* a
> node, you insert it (creating it first, if necessary) before
> returning.
>
> The value to be searched for is the data item passed in the argument
> id. The while loop uses true as its condition because it doesn't care
> if it encounters a node with the same value as id; it treats another
> node with the same key value as if it were simply greater than the key
> value. (We'll return to the subject of duplicate nodes later in this
> chapter.)
>
> A place to insert a new node will always be found (unless you run out
> of memory); when it is, and the new node is attached, the while loop
> exits with a return state- ment.
>
> Here's the code for the insert() function:
>
> public void insert(int id, double dd)
>
> {
>
> Node newNode = new Node(); // make new node newNode.iData = id; //
> insert data newNode.dData = dd;
>
> if(root==null) // no node in root root = newNode;
>
> else // root occupied
>
> {
>
> Node current = root; // start at root Node parent;
>
> while(true) // (exits internally)
>
> {
>
> parent = current;
>
> if(id \< current.iData) // go left?
>
> {
>
> current = current.leftChild;
>
> if(current == null) // if end of the line,
>
> { // insert on left parent.leftChild = newNode;
>
> return;
>
> }
>
> } // end if go left
>
> else // or go right?
>
> {

Traversing the Tree 381

> current = current.rightChild;
>
> if(current == null) // if end of the line
>
> { // insert on right parent.rightChild = newNode;
>
> return;
>
> }
>
> } // end else go right

} // end while

} // end else not root

> } // end insert()
>
> //
> \-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\--
>
> We use a new variable, parent (the parent of current), to remember the
> last non-null node we encountered (50 in Figure 8.8). This is
> necessary because current is set to null in the process of discovering
> that its previous value did not have an appropriate child. If we
> didn't save parent, we would lose track of where we were.
>
> To insert the new node, change the appropriate child pointer in parent
> (the last non- null node you encountered) to point to the new node. If
> you were looking unsuc- cessfully for parent's left child, you attach
> the new node as parent's left child; if you were looking for its right
> child, you attach the new node as its right child. In Figure 8.8, 45
> is attached as the left child of 50.

#### Traversing the Tree

> Traversing a tree means visiting each node in a specified order. This
> process is not as commonly used as finding, inserting, and deleting
> nodes. One reason for this is that traversal is not particularly fast.
> But traversing a tree is useful in some circumstances, and it's
> theoretically interesting. (It's also simpler than deletion, the
> discussion of which we want to defer as long as possible.)
>
> There are three simple ways to traverse a tree. They're called
> *preorder*, *inorder*, and *postorder*. The order most commonly used
> for binary search trees is inorder, so let's look at that first and
> then return briefly to the other two.

##### Inorder Traversal

> An inorder traversal of a binary search tree will cause all the nodes
> to be visited in *ascending order*, based on their key values. If you
> want to create a sorted list of the data in a binary tree, this is one
> way to do it.
>
> The simplest way to carry out a traversal is the use of recursion
> (discussed in Chapter 6, "Recursion"). A recursive method to traverse
> the entire tree is called with a node as an argument. Initially, this
> node is the root. The method needs to do only three things:
>
> 382 **CHAPTER 8** Binary Trees

1.  Call itself to traverse the node's left subtree.

2.  Visit the node.

3.  Call itself to traverse the node's right subtree.

> Remember that *visiting* a node means doing something to it:
> displaying it, writing it to a file, or whatever.
>
> Traversals work with any binary tree, not just with binary search
> trees. The traversal mechanism doesn't pay any attention to the key
> values of the nodes; it only concerns itself with whether a node has
> children.

##### Java Code for Traversing

> The actual code for inorder traversal is so simple we show it before
> seeing how traversal looks in the Workshop applet. The routine,
> inOrder(), performs the three steps already described. The visit to
> the node consists of displaying the contents of the node. Like any
> recursive function, it must have a base case---the condition that
> causes the routine to return immediately, without calling itself. In
> inOrder() this happens when the node passed as an argument is null.
> Here's the code for the inOrder() method:
>
> private void inOrder(node localRoot)
>
> {
>
> if(localRoot != null)
>
> {
>
> inOrder(localRoot.leftChild);
>
> System.out.print(localRoot.iData + " ");
> inOrder(localRoot.rightChild);
>
> }
>
> }
>
> This method is initially called with the root as an argument:
>
> inOrder(root);
>
> After that, it's on its own, calling itself recursively until there
> are no more nodes to visit.

##### Traversing a Three-Node Tree

> Let's look at a simple example to get an idea of how this recursive
> traversal routine works. Imagine traversing a tree with only three
> nodes: a root (A), with a left child (B), and a right child (C), as
> shown in Figure 8.9.

Traversing the Tree 383

![](media/image71.png)

> inOrder (A)
>
> inOrder (C)

######  

> ***FIGURE 8.9*** The inOrder() method applied to a three-node tree.
>
> We start by calling inOrder() with the root A as an argument. This
> incarnation of inOrder() we'll call inOrder(A). inOrder(A) first calls
> inOrder() with its left child, B, as an argument. This second
> incarnation of inOrder() we'll call inOrder(B).
>
> inOrder(B) now calls itself with its left child as an argument.
> However, it has no left child, so this argument is null. This creates
> an invocation of inorder() we could call inOrder(null). There are now
> three instances of inOrder() in existence: inOrder(A), inOrder(B), and
> inOrder(null). However, inOrder(null) returns immediately when it
> finds its argument is null. (We all have days like that.)
>
> Now inOrder(B) goes on to visit B; we'll assume this means to display
> it. Then inOrder(B) calls inOrder() again, with its right child as an
> argument. Again this argu- ment is null, so the second inorder(null)
> returns immediately. Now inOrder(B) has carried out steps 1, 2, and 3,
> so it returns (and thereby ceases to exist).
>
> 384 **CHAPTER 8** Binary Trees
>
> Now we're back to inOrder(A), just returning from traversing A's left
> child. We visit A and then call inOrder() again with C as an argument,
> creating inOrder(C). Like inOrder(B), inOrder(C) has no children, so
> step 1 returns with no action, step 2 visits C, and step 3 returns
> with no action. inOrder(B) now returns to inOrder(A).
>
> However, inOrder(A) is now done, so it returns and the entire
> traversal is complete. The order in which the nodes were visited is A,
> B, C; they have been visited *inorder*. In a binary search tree this
> would be the order of ascending keys.
>
> More complex trees are handled similarly. The inOrder() function calls
> itself for each node, until it has worked its way through the entire
> tree.

##### Traversing with the Workshop Applet

> To see what a traversal looks like with the Workshop applet,
> repeatedly press the Trav button. (You don't need to type in any
> numbers.)
>
> Here's what happens when you use the Tree Workshop applet to traverse
> inorder the tree shown in Figure 8.10. This is slightly more complex
> than the three-node tree seen previously. The red arrow starts at the
> root. Table 8.1 shows the sequence of node keys and the corresponding
> messages. The key sequence is displayed at the bottom of the Workshop
> applet screen.
>
> ![](media/image58.png)13. Visit 50
>
> ![](media/image84.png){width="0.10647200349956255in"
> height="0.27112423447069117in"}![](media/image85.png){width="0.10648622047244094in"
> height="0.27112423447069117in"}![](media/image86.png){width="0.10647200349956255in"
> height="0.27112423447069117in"}![](media/image87.png){width="0.10648622047244094in"
> height="0.27112423447069117in"}3 5 9 11

4.  Visit 20

> ***FIGURE 8.10*** Traversing a tree inorder.

Traversing the Tree 385

+-----------------+-----------------+-----------------+-----------------+
| ***TABLE 8.1*** | > Workshop      | > Traversal     |                 |
|                 | > Applet        |                 |                 |
+=================+=================+=================+=================+
| **Step**        | > **Red**       |                 | > **List of**   |
|                 | >               |                 | >               |
|                 | > **Arrow**     |                 | > **Nodes**     |
+-----------------+-----------------+-----------------+-----------------+
| **Number**      | > **on Node**   | > **Message**   | > **Visited**   |
+-----------------+-----------------+-----------------+-----------------+
| 1               | > 50 (root)     | > Will check    |                 |
|                 |                 | > left child    |                 |
+-----------------+-----------------+-----------------+-----------------+
| 2               | > 30            | > Will check    |                 |
|                 |                 | > left child    |                 |
+-----------------+-----------------+-----------------+-----------------+
| 3               | > 20            | > Will check    |                 |
|                 |                 | > left child    |                 |
+-----------------+-----------------+-----------------+-----------------+
| 4               | > 20            | > Will visit    |                 |
|                 |                 | > this node     |                 |
+-----------------+-----------------+-----------------+-----------------+
| 5               | > 20            | > Will check    | > 20            |
|                 |                 | > right child   |                 |
+-----------------+-----------------+-----------------+-----------------+
| 6               | > 20            | > Will go to    | > 20            |
|                 |                 | > root of       |                 |
|                 |                 | > previous      |                 |
|                 |                 | > subtree       |                 |
+-----------------+-----------------+-----------------+-----------------+
| 7               | > 30            | > Will visit    | > 20            |
|                 |                 | > this node     |                 |
+-----------------+-----------------+-----------------+-----------------+
| 8               | > 30            | > Will check    | > 20 30         |
|                 |                 | > right child   |                 |
+-----------------+-----------------+-----------------+-----------------+
| 9               | > 40            | > Will check    | > 20 30         |
|                 |                 | > left child    |                 |
+-----------------+-----------------+-----------------+-----------------+
| 10              | > 40            | > Will visit    | > 20 30         |
|                 |                 | > this node     |                 |
+-----------------+-----------------+-----------------+-----------------+
| 11              | > 40            | > Will check    | > 20 30 40      |
|                 |                 | > right child   |                 |
+-----------------+-----------------+-----------------+-----------------+
| 12              | > 40            | > Will go to    | > 20 30 40      |
|                 |                 | > root of       |                 |
|                 |                 | > previous      |                 |
|                 |                 | > subtree       |                 |
+-----------------+-----------------+-----------------+-----------------+
| 13              | > 50            | > Will visit    | > 20 30 40      |
|                 |                 | > this node     |                 |
+-----------------+-----------------+-----------------+-----------------+
| 14              | > 50            | > Will check    | > 20 30 40 50   |
|                 |                 | > right child   |                 |
+-----------------+-----------------+-----------------+-----------------+
| 15              | > 60            | > Will check    | > 20 30 40 50   |
|                 |                 | > left child    |                 |
+-----------------+-----------------+-----------------+-----------------+
| 16              | > 60            | > Will visit    | > 20 30 40 50   |
|                 |                 | > this node     |                 |
+-----------------+-----------------+-----------------+-----------------+
| 17              | > 60            | > Will check    | > 20 30 40 50   |
|                 |                 | > right child   | > 60            |
+-----------------+-----------------+-----------------+-----------------+
| 18              | > 60            | > Will go to    | > 20 30 40 50   |
|                 |                 | > root of       | > 60            |
|                 |                 | > previous      |                 |
|                 |                 | > subtree       |                 |
+-----------------+-----------------+-----------------+-----------------+
| 19              | > 50            | > Done          | > 20 30 40 50   |
|                 |                 | > traversal     | > 60            |
+-----------------+-----------------+-----------------+-----------------+

> It may not be obvious, but for each node, the routine traverses the
> node's left subtree, visits the node, and traverses the right subtree.
> For example, for node 30 this happens in steps 2, 7, and 8.
>
> The traversal algorithm isn't as complicated as it looks. The best way
> to get a feel for what's happening is to traverse a variety of
> different trees with the Workshop applet.

##### Preorder and Postorder Traversals

> You can traverse the tree in two ways besides inorder; they're called
> preorder and postorder. It's fairly clear why you might want to
> traverse a tree inorder, but the motivation for preorder and postorder
> traversals is more obscure. However, these traversals are indeed
> useful if you're writing programs that *parse* or analyze algebraic
> expressions. Let's see why that should be true.
>
> A binary tree (not a binary search tree) can be used to represent an
> algebraic expres- sion that involves the binary arithmetic operators
> +, --, /, and \*. The root node holds an operator, and the other nodes
> hold either a variable name (like A, B, or C), or another operator.
> Each subtree is a valid algebraic expression.
>
> 386 **CHAPTER 8** Binary Trees

![](media/image88.png)

> Infix: A\*(B+C) Prefix: \*A+BC Postfix: ABC+\*
>
> ***FIGURE 8.11*** Tree representing an algebraic expression.
>
> For example, the binary tree shown in Figure 8.11 represents the
> algebraic expression A\*(B+C)
>
> This is called *infix* notation; it's the notation normally used in
> algebra. (For more on infix and postfix, see the section "Parsing
> Arithmetic Expressions" in Chapter 4, "Stacks and Queues.") Traversing
> the tree inorder will generate the correct inorder sequence A\*B+C,
> but you'll need to insert the parentheses yourself.
>
> What does all this have to do with preorder and postorder traversals?
> Let's see what's involved. For these other traversals the same three
> steps are used as for inorder, but in a different sequence. Here's the
> sequence for a preorder() method:

1.  Visit the node.

2.  Call itself to traverse the node's left subtree.

3.  Call itself to traverse the node's right subtree.

> Traversing the tree shown in Figure 8.11 using preorder would generate
> the expression
>
> \*A+BC
>
> This is called *prefix* notation. One of the nice things about it is
> that parentheses are never required; the expression is unambiguous
> without them. Starting on the left, each operator is applied to the
> next two things in the expression. For the first opera- tor, \*, these
> two things are A and +BC. For the second operator, +, the two things
> are B and C, so this last expression is B+C in inorder notation.
> Inserting that into the original expression \*A+BC (preorder) gives us
> A\*(B+C) in inorder. By using different traversals of the tree, we can
> transform one form of the algebraic expression into another.

Traversing the Tree 387

> The third kind of traversal, postorder, contains the three steps
> arranged in yet another way:

1.  Call itself to traverse the node's left subtree.

2.  Call itself to traverse the node's right subtree.

3.  Visit the node.

> For the tree in Figure 8.11, visiting the nodes with a postorder
> traversal would generate the expression
>
> ABC+\*
>
> This is called *postfix* notation. It means "apply the last operator
> in the expression, \*, to the first and second things." The first
> thing is A, and the second thing is BC+.
>
> BC+ means "apply the last operator in the expression, +, to the first
> and second things." The first thing is B and the second thing is C, so
> this gives us (B+C) in infix. Inserting this in the original
> expression ABC+\* (postfix) gives us A\*(B+C) postfix.
>
> **[NOTE ]{.underline}**
>
> The code in Listing 8.1 contains methods for preorder and postorder
> traversals, as well as for inorder.
>
> We won't show the details here, but you can fairly easily construct a
> tree like that in Figure 8.11 using a postfix expression as input. The
> approach is analogous to that of evaluating a postfix expression,
> which we saw in the postfix.java program (Listing

1.  in Chapter 4). However, instead of storing operands on the stack, we
    store entire subtrees. We read along the postfix string as we did in
    postfix.java. Here are the steps when we encounter an operand:

    1.  Make a tree with one node that holds the operand.

    2.  Push this tree onto the stack.

> Here are the steps when we encounter an operator:

1.  Pop two operand trees B and C off the stack.

2.  Create a new tree A with the operator in its root.

3.  Attach B as the right child of A.

4.  Attach C as the left child of A.

5.  Push the resulting tree back on the stack.

> 388 **CHAPTER 8** Binary Trees
>
> When you're done evaluating the postfix string, you pop the one
> remaining item off the stack. Somewhat amazingly, this item is a
> complete tree depicting the algebraic expression. You can see the
> prefix and infix representations of the original postfix (and recover
> the postfix expression) by traversing the tree as we described. We'll
> leave an implementation of this process as an exercise.

#### Finding Maximum and Minimum Values

> Incidentally, we should note how easy it is to find the maximum and
> minimum values in a binary search tree. In fact, this process is so
> easy we don't include it as an option in the Workshop applet, nor show
> code for it in Listing 8.1. Still, understand- ing how it works is
> important.
>
> For the minimum, go to the left child of the root; then go to the left
> child of that child, and so on, until you come to a node that has no
> left child. This node is the minimum, as shown in Figure 8.12.
>
> ![](media/image91.png)63
>
> 47 71
>
> Minimum
>
> 22 53 67

11 33 50 60

17 49 51

> ***FIGURE 8.12*** Minimum value of a tree.
>
> Here's some code that returns the node with the minimum key value:
>
> public Node minimum() // returns node with minimum key value
>
> {
>
> Node current, last;
>
> current = root; // start at root
>
> while(current != null) // until the bottom,

Deleting a Node 389

> {
>
> last = current; // remember node current = current.leftChild; // go to
> left child
>
> }
>
> return last;
>
> }
>
> We'll need to know about finding the minimum value when we set about
> deleting a node.
>
> For the *maximum* value in the tree, follow the same procedure, but go
> from right child to right child until you find a node with no right
> child. This node is the maximum. The code is the same except that the
> last statement in the loop is
>
> current = current.rightChild; // go to right child

#### Deleting a Node

> Deleting a node is the most complicated common operation required for
> binary search trees. However, deletion is important in many tree
> applications, and studying the details builds character.
>
> You start by finding the node you want to delete, using the same
> approach we saw in find() and insert(). When you've found the node,
> there are three cases to consider:

1.  The node to be deleted is a leaf (has no children).

2.  The node to be deleted has one child.

3.  The node to be deleted has two children.

> We'll look at these three cases in turn. The first is easy; the
> second, almost as easy; and the third, quite complicated.

##### Case 1: The Node to Be Deleted Has No Children

> To delete a leaf node, you simply change the appropriate child field
> in the node's parent to point to null, instead of to the node. The
> node will still exist, but it will no longer be part of the tree. This
> is shown in Figure 8.13.
>
> Because of Java's garbage collection feature, we don't need to worry
> about explicitly deleting the node itself. When Java realizes that
> nothing in the program refers to the node, it will be removed from
> memory. (In C and C++ you would need to execute free() or delete() to
> remove the node from memory.)
>
> 390 **CHAPTER 8** Binary Trees
>
> ![](media/image99.png)10 10

5 5

> null
>
> 3 7 3 7
>
> Awaiting garbage collection

a)  Before deletion b) After deletion

> ***FIGURE 8.13*** Deleting a node with no children.

####### Using the Workshop Applet to Delete a Node with No Children

> Assume you're going to delete node 7 in Figure 8.13. Press the Del
> button and enter
>
> 7 when prompted. Again, the node must be found before it can be
> deleted. Repeatedly pressing Del will take you from 10 to 5 to 7. When
> the node is found, it's deleted without incident.

####### Java Code to Delete a Node with No Children

> The first part of the delete() routine is similar to find() and
> insert(). It involves finding the node to be deleted. As with
> insert(), we need to remember the parent of the node to be deleted so
> we can modify its child fields. If we find the node, we drop out of
> the while loop with parent containing the node to be deleted. If we
> can't find it, we return from delete() with a value of false.
>
> public boolean delete(int key) // delete node with given key
>
> { // (assumes non-empty list) Node current = root;
>
> Node parent = root;
>
> boolean isLeftChild = true;
>
> while(current.iData != key) // search for node
>
> {
>
> parent = current;
>
> if(key \< current.iData) // go left?
>
> {
>
> isLeftChild = true;
>
> current = current.leftChild;
>
> }
>
> else // or go right?
>
> {

Deleting a Node 391

> isLeftChild = false;
>
> current = current.rightChild;
>
> }
>
> if(current == null) // end of the line, return false; // didn't find
> it
>
> } // end while
>
> // found node to delete
>
> // continues\...
>
> }
>
> After we've found the node, we check first to verify that it has no
> children. When this is true, we check the special case of the root. If
> that's the node to be deleted, we simply set it to null; this empties
> the tree. Otherwise, we set the parent's leftChild or rightChild field
> to null to disconnect the parent from the node.
>
> // delete() continued\...
>
> // if no children, simply delete it if(current.leftChild==null &&
>
> current.rightChild==null)
>
> {
>
> if(current == root) // if root, root = null; // tree is empty
>
> else if(isLeftChild)
>
> parent.leftChild = null; // disconnect else // from parent
>
> parent.rightChild = null;
>
> }
>
> // continues\...

##### Case 2: The Node to Be Deleted Has One Child

> This second case isn't so bad either. The node has only two
> connections: to its parent and to its only child. You want to "snip"
> the node out of this sequence by connect- ing its parent directly to
> its child. This process involves changing the appropriate reference in
> the parent (leftChild or rightChild) to point to the deleted node's
> child. This situation is shown in Figure 8.14.

####### Using the Workshop Applet to Delete a Node with One Child

> Let's assume we're using the Workshop applet on the tree in Figure
> 8.14 and deleting node 71, which has a left child but no right child.
> Press Del and enter 71 when prompted. Keep pressing Del until the
> arrow rests on 71. Node 71 has only one child, 63. It doesn't matter
> whether 63 has children of its own; in this case it has one: 67.
>
> 392 **CHAPTER 8** Binary Trees

![](media/image110.png)

a)  Before deletion

> ***FIGURE 8.14*** Deleting a node with one child.

b)  After deletion

> Pressing Del once more causes 71 to be deleted. Its place is taken by
> its left child, 63. In fact, the entire subtree of which 63 is the
> root is moved up and plugged in as the new right child of 52.
>
> Use the Workshop applet to generate new trees with one-child nodes,
> and see what happens when you delete them. Look for the subtree whose
> root is the deleted node's child. No matter how complicated this
> subtree is, it's simply moved up and plugged in as the new child of
> the deleted node's parent.

####### Java Code to Delete a Node with One Child

> The following code shows how to deal with the one-child situation.
> There are four variations: The child of the node to be deleted may be
> either a left or right child, and for each of these cases the node to
> be deleted may be either the left or right child of its parent.
>
> There is also a specialized situation: the node to be deleted may be
> the root, in which case it has no parent and is simply replaced by the
> appropriate subtree. Here's the code (which continues from the end of
> the no-child code fragment shown earlier):
>
> // delete() continued\...
>
> // if no right child, replace with left subtree else
> if(current.rightChild==null)

if(current == root)

Deleting a Node 393

> root = current.leftChild;
>
> else if(isLeftChild) // left child of parent parent.leftChild =
> current.leftChild;
>
> else // right child of parent parent.rightChild = current.leftChild;
>
> // if no left child, replace with right subtree else
> if(current.leftChild==null)
>
> if(current == root)
>
> root = current.rightChild;
>
> else if(isLeftChild) // left child of parent parent.leftChild =
> current.rightChild;
>
> else // right child of parent parent.rightChild = current.rightChild;
>
> // continued\...
>
> Notice that working with references makes it easy to move an entire
> subtree. You do this by simply disconnecting the old reference to the
> subtree and creating a new reference to it somewhere else. Although
> there may be lots of nodes in the subtree, you don't need to worry
> about moving them individually. In fact, they "move" only in the sense
> of being conceptually in different positions relative to the other
> nodes. As far as the program is concerned, only the reference to the
> root of the subtree has changed.

##### Case 3: The Node to Be Deleted Has Two Children

> Now the fun begins. If the deleted node has two children, you can't
> just replace it with one of these children, at least if the child has
> its own children. Why not?
>
> Examine Figure 8.15, and imagine deleting node 25 and replacing it
> with its right subtree, whose root is 35. Which left child would 35
> have? The deleted node's left child, 15, or the new node's left child,
> 30? In either case 30 would be in the wrong place, but we can't just
> throw it away.
>
> We need another approach. The good news is that there's a trick. The
> bad news is that, even with the trick, there are a lot of special
> cases to consider. Remember that in a binary search tree the nodes are
> arranged in order of ascending keys. For each node, the node with the
> next-highest key is called its *inorder successor*, or simply its
> successor. In Figure 8.15a, node 30 is the successor of node 25.
>
> Here's the trick: To delete a node with two children, *replace the
> node with its inorder successor*. Figure 8.16 shows a deleted node
> being replaced by its successor. Notice that the nodes are still in
> order. (There's more to it if the successor itself has children; we'll
> look at that possibility in a moment.)
>
> 394 **CHAPTER 8** Binary Trees
>
> ![](media/image123.png)![](media/image128.png)50
>
> To be deleted 25
>
> 15 35
>
> Root of right subtree
>
> 5 20 30 40

a)  Before deletion b) After deletion

> ***FIGURE 8.15*** Cannot replace with subtree.

![](media/image132.png)![](media/image136.png)

> Successor to 25

a.  Before deletion b) After deletion

> ***FIGURE 8.16*** Node replaced by its successor.

####### Finding the Successor

> How do you find the successor of a node? As a human being, you can do
> this quickly (for small trees, anyway). Just take a quick glance at
> the tree and find the next-largest number following the key of the
> node to be deleted. In Figure 8.16 it doesn't take

Deleting a Node 395

> long to see that the successor of 25 is 30. There's just no other
> number that is greater than 25 and also smaller than 35. However, the
> computer can't do things "at a glance"; it needs an algorithm. Here it
> is:
>
> First, the program goes to the original node's right child, which must
> have a key larger than the node. Then it goes to this right child's
> left child (if it has one), and to this left child's left child, and
> so on, following down the path of left children. The last left child
> in this path is the successor of the original node, as shown in Figure
> 8.17.
>
> ![](media/image142.png)To find successor of this node
>
> 38 Go to
>
> right child
>
> 26 Go to 72
>
> left child
>
> 55 90
>
> Go to left child
>
> Successor [ ]{.underline} 41 60 78 92
>
> No left 43 74
>
> child
>
> ***FIGURE 8.17*** Finding the successor.
>
> Why does this algorithm work? What we're really looking for is *the
> smallest of the set of nodes that are larger than the original node*.
> When you go to the original node's right child, all the nodes in the
> resulting subtree are greater than the original node because this is
> how a binary search tree is defined. Now we want the smallest value in
> this subtree. As we learned, you can find the minimum value in a
> subtree by following the path down all the left children. Thus, this
> algorithm finds the minimum value that is greater than the original
> node; this is what we mean by its successor.
>
> If the right child of the original node has no left children, this
> right child is itself the successor, as shown in Figure 8.18.
>
> 396 **CHAPTER 8** Binary Trees

![](media/image154.png)

> ***FIGURE 8.18*** The right child is the successor.

####### Using the Workshop Applet to Delete a Node with Two Children

> Generate a tree with the Workshop applet, and pick a node with two
> children. Now mentally figure out which node is its successor, by
> going to its right child and then following down the line of this
> right child's left children (if it has any). You may want to make sure
> the successor has no children of its own. If it does, the situation
> gets more complicated because entire subtrees are moved around, rather
> than a single node.
>
> After you've chosen a node to delete, click the Del button. You'll be
> asked for the key value of the node to delete. When you've specified
> it, repeated presses of the Del button will show the red arrow
> searching down the tree to the designated node.
>
> When the node is deleted, it's replaced by its successor.
>
> Let's assume you use the Workshop applet to delete the node with key
> 30 from the example shown earlier in Figure 8.15. The red arrow will
> go from the root at 50 to 25; then 25 will be replaced by 30.

####### Java Code to Find the Successor

> Here's some code for a method getSuccessor(), which returns the
> successor of the node specified as its delNode argument. (This routine
> assumes that delNode does indeed have a right child, but we know this
> is true because we've already determined that the node to be deleted
> has two children.)
>
> // returns node with next-highest value after delNode
>
> // goes to right child, then right child's left descendants
>
> private node getSuccessor(node delNode)
>
> {
>
> Node successorParent = delNode;

Deleting a Node 397

> Node successor = delNode;
>
> Node current = delNode.rightChild; // go to right child while(current
> != null) // until no more
>
> { // left children,
>
> successorParent = successor; successor = current;
>
> current = current.leftChild; // go to left child
>
> }
>
> // if successor not if(successor != delNode.rightChild) // right
> child,
>
> { // make connections
>
> successorParent.leftChild = successor.rightChild; successor.rightChild
> = delNode.rightChild;
>
> }
>
> return successor;
>
> }
>
> The routine first goes to delNode's right child and then, in the while
> loop, follows down the path of all this right child's left children.
> When the while loop exits, successor contains delNode's successor.
>
> When we've found the successor, we may need to access its parent, so
> within the
>
> while loop we also keep track of the parent of the current node.
>
> The getSuccessor() routine carries out two additional operations in
> addition to finding the successor. However, to understand them, we
> need to step back and consider the big picture.
>
> As we've seen, the successor node can occupy one of two possible
> positions relative to current, the node to be deleted. The successor
> can be current's right child, or it can be one of this right child's
> left descendants. We'll look at these two situations in turn.

####### Successor Is Right Child of delNode

> If successor is the right child of current, things are simplified
> somewhat because we can simply move the subtree of which successor is
> the root and plug it in where the deleted node was. This operation
> requires only two steps:

1.  Unplug current from the rightChild field of its parent (or leftChild
    field if appropriate), and set this field to point to successor.

2.  Unplug current's left child from current, and plug it into the
    leftChild field of

> successor.
>
> 398 **CHAPTER 8** Binary Trees
>
> Here are the code statements that carry out these steps, excerpted
> from delete():

1.  parent.rightChild = successor;

2.  successor.leftChild = current.leftChild;

> This situation is summarized in Figure 8.19, which shows the
> connections affected by these two steps.

![](media/image160.png)![](media/image140.png)

a.  Before deletion b) After deletion

> ***FIGURE 8.19*** Deletion when the successor is the right child.
>
> Here's the code in context (a continuation of the else-if ladder shown
> earlier):
>
> // delete() continued
>
> else // two children, so replace with inorder successor
>
> {
>
> // get successor of node to delete (current) Node successor =
> getSuccessor(current);
>
> // connect parent of current to successor instead if(current == root)
>
> root = successor; else if(isLeftChild)
>
> parent.leftChild = successor; else
>
> parent.rightChild = successor;
>
> // connect successor to current's left child successor.leftChild =
> current.leftChild;
>
> } // end else two children
>
> // (successor cannot have a left child)

Deleting a Node 399

> return true;
>
> } // end delete()
>
> Notice that this is---finally---the end of the delete() routine. Let's
> review the code for these two steps:

-   Step 1: If the node to be deleted, current, is the root, it has no
    parent so we merely set the root to the successor. Otherwise, the
    node to be deleted can be either a left or right child (Figure 8.19
    shows it as a right child), so we set the appropriate field in its
    parent to point to successor. When delete() returns and current goes
    out of scope, the node referred to by current will have no refer-
    ences to it, so it will be discarded during Java's next garbage
    collection.

-   Step 2: We set the left child of successor to point to current's
    left child.

> What happens if the successor has children of its own? First of all,
> *a successor node is guaranteed not to have a left child*. This is
> true whether the successor is the right child of the node to be
> deleted or one of this right child's left children. How do we know
> this?
>
> Well, remember that the algorithm we use to determine the successor
> goes to the right child first and then to any left children of that
> right child. It stops when it gets to a node with no left child, so
> the algorithm itself determines that the successor can't have any left
> children. If it did, that left child would be the successor instead.
>
> You can check this out on the Workshop applet. No matter how many
> trees you make, you'll never find a situation in which a node's
> successor has a left child (assuming the original node has two
> children, which is the situation that leads to all this trouble in the
> first place).
>
> On the other hand, the successor may very well have a right child.
> This isn't much of a problem when the successor is the right child of
> the node to be deleted. When we move the successor, its right subtree
> simply follows along with it. There's no conflict with the right child
> of the node being deleted because the successor *is* this right child.
>
> In the next section we'll see that a successor's right child needs
> more attention if the successor is not the right child of the node to
> be deleted.

####### Successor Is Left Descendant of Right Child of delNode

> If successor is a left descendant of the right child of the node to be
> deleted, four steps are required to perform the deletion:

1.  Plug the right child of successor into the leftChild field of the
    successor's parent.

2.  Plug the right child of the node to be deleted into the rightChild
    field of

> successor.
>
> 400 **CHAPTER 8** Binary Trees

3.  Unplug current from the rightChild field of its parent, and set this
    field to point to successor.

4.  Unplug current's left child from current, and plug it into the
    leftChild field of

> successor.
>
> Steps 1 and 2 are handled in the getSuccessor() routine, while 3 and 4
> are carried out in delete(). Figure 8.20 shows the connections
> affected by these four steps.

![](media/image169.png)50 Parent

Step 3

75

> To be deleted
>
> ![](media/image177.png)Successor's

Step 4 Step 2

> parent
>
> 62 87
>
> Step 1
>
> Successor 77 93
>
> Cannot [ ]{.underline} exist

Step 1

79

> Successor's right child

a)  Before deletion

> ***FIGURE 8.20*** Deletion when the successor is the left child.
>
> Here's the code for these four steps:

1.  successorParent.leftChild = successor.rightChild;

2.  successor.rightChild = delNode.rightChild;

3.  parent.rightChild = successor;

4.  successor.leftChild = current.leftChild;

<!-- -->

b)  After deletion

> (Step 3 could also refer to the left child of its parent.) The numbers
> in Figure 8.20 show the connections affected by the four steps. Step 1
> in effect *replaces the successor with its right subtree*. Step 2
> keeps the right child of the deleted node in its proper place (this
> happens automatically when the successor is the right child of the
> deleted node). Steps 1 and 2 are carried out in the if statement that
> ends the getSuccessor() method shown earlier. Here's that statement
> again:
>
> The Efficiency of Binary Trees 401
>
> // if successor not if(successor != delNode.rightChild) // right
> child,
>
> { // make connections
>
> successorParent.leftChild = successor.rightChild; successor.rightChild
> = delNode.rightChild;
>
> }
>
> These steps are more convenient to perform here than in delete(),
> because in getSuccessor() we can easily figure out where the
> successor's parent is while we're descending the tree to find the
> successor.
>
> Steps 3 and 4 we've seen already; they're the same as steps 1 and 2 in
> the case where the successor is the right child of the node to be
> deleted, and the code is in the if statement at the end of delete().

####### Is Deletion Necessary?

> If you've come this far, you can see that deletion is fairly involved.
> In fact, it's so complicated that some programmers try to sidestep it
> altogether. They add a new Boolean field to the node class, called
> something like isDeleted. To delete a node, they simply set this field
> to true. Then other operations, like find(), check this field to be
> sure the node isn't marked as deleted before working with it. This
> way, deleting a node doesn't change the structure of the tree. Of
> course, it also means that memory can fill up with "deleted" nodes.
>
> This approach is a bit of a cop-out, but it may be appropriate where
> there won't be many deletions in a tree. (If ex-employees remain in
> the personnel file forever, for example.)

#### The Efficiency of Binary Trees

> As you've seen, most operations with trees involve descending the tree
> from level to level to find a particular node. How long does it take
> to do this? In a full tree, about half the nodes are on the bottom
> level. (More accurately, if it's full, there's one more node on the
> bottom row than in the rest of the tree.) Thus, about half of all
> searches or insertions or deletions require finding a node on the
> lowest level. (An additional quarter of these operations require
> finding the node on the next-to-lowest level, and so on.)
>
> During a search we need to visit one node on each level. So we can get
> a good idea how long it takes to carry out these operations by knowing
> how many levels there are. Assuming a full tree, Table 8.2 shows how
> many levels are necessary to hold a given number of nodes.
>
> 402 **CHAPTER 8** Binary Trees
>
> ***TABLE 8.2*** Number of Levels for Specified Number of Nodes
>
> **Number of Nodes Number of Levels**
>
> 1 1
>
> 3 2
>
> 7 3
>
> 15 4
>
> 31 5
>
> ... ...
>
> 1,023 10
>
> ... ...
>
> 32,767 15
>
> ... ...
>
> 1,048,575 20
>
> ... ...
>
> 33,554,432 25
>
> ... ...
>
> 1,073,741,824 30
>
> This situation is very much like the ordered array discussed in
> Chapter 2. In that case, the number of comparisons for a binary search
> was approximately equal to the base 2 logarithm of the number of cells
> in the array. Here, if we call the number of nodes in the first column
> N, and the number of levels in the second column L, we can say that N
> is 1 less than 2 raised to the power L, or
>
> N = 2L -- 1
>
> Adding 1 to both sides of the equation, we have N + 1 = 2L
>
> This is equivalent to L = log2(N + 1)
>
> Thus, the time needed to carry out the common tree operations is
> proportional to
>
> the base 2 log of N. In Big O notation we say such operations take
> O(logN) time.
>
> If the tree isn't full, analysis is difficult. We can say that for a
> tree with a given number of levels, average search times will be
> shorter for the non-full tree than the full tree because fewer
> searches will proceed to lower levels.
>
> Compare the tree to the other data storage structures we've discussed
> so far. In an unordered array or a linked list containing 1,000,000
> items, finding the item you want takes, on the average, 500,000
> comparisons. But in a tree of 1,000,000 items, only 20 (or fewer)
> comparisons are required.
>
> Trees Represented as Arrays 403
>
> In an ordered array you can find an item equally quickly, but
> inserting an item requires, on the average, moving 500,000 items.
> Inserting an item in a tree with 1,000,000 items requires 20 or fewer
> comparisons, plus a small amount of time to connect the item.
>
> Similarly, deleting an item from a 1,000,000-item array requires
> moving an average of 500,000 items, while deleting an item from a
> 1,000,000-node tree requires 20 or fewer comparisons to find the item,
> plus (possibly) a few more comparisons to find its successor, plus a
> short time to disconnect the item and connect its successor.
>
> Thus, a tree provides high efficiency for all the common data storage
> operations.
>
> Traversing is not as fast as the other operations. However, traversals
> are probably not very commonly carried out in a typical large
> database. They're more appropriate when a tree is used as an aid to
> parsing algebraic or similar expressions, which are probably not too
> long anyway.

#### Trees Represented as Arrays

> Our code examples are based on the idea that a tree's edges are
> represented by leftChild and rightChild references in each node.
> However, there's a completely different way to represent a tree: with
> an array.
>
> In the array approach, the nodes are stored in an array and are not
> linked by refer- ences. The position of the node in the array
> corresponds to its position in the tree. The node at index 0 is the
> root, the node at index 1 is the root's left child, and so on,
> progressing from left to right along each level of the tree. This is
> shown in Figure 8.21.
>
> Every position in the tree, whether it represents an existing node or
> not, corresponds to a cell in the array. Adding a node at a given
> position in the tree means inserting the node into the equivalent cell
> in the array. Cells representing tree positions with no nodes are
> filled with 0 or null.
>
> With this scheme, a node's children and parent can be found by
> applying some simple arithmetic to the node's index number in the
> array. If a node's index number is index, this node's left child is
>
> 2\*index + 1
>
> its right child is
>
> 2\*index + 2
>
> and its parent is
>
> (index-1) / 2
>
> 404 **CHAPTER 8** Binary Trees
>
> (where the / character indicates integer division with no remainder).
> You can check this out by looking at Figure 8.21.

![](media/image179.png)Array

0

1

2

3

4

5

50

0

25 75

> 1 2
>
> 6 37
>
> 62 84
>
> 3 4 5 6
>
> 7
>
> 8
>
> 9
>
> 10 31 43 55 92
>
> 7 8 9 10 11 12 13 14
>
> 11
>
> 12
>
> 13
>
> 14
>
> ***FIGURE 8.21*** Tree represented by an array.
>
> In most situations, representing a tree with an array isn't very
> efficient. Unfilled nodes and deleted nodes leave holes in the array,
> wasting memory. Even worse, when deletion of a node involves moving
> subtrees, every node in the subtree must be moved to its new location
> in the array, which is time-consuming in large trees.
>
> However, if deletions aren't allowed, the array representation may be
> useful, espe- cially if obtaining memory for each node dynamically is,
> for some reason, too time- consuming. The array representation may
> also be useful in special situations. The tree in the Workshop applet,
> for example, is represented internally as an array to make it easy to
> map the nodes from the array to fixed locations on the screen display.

#### Duplicate Keys

> As in other data structures, the problem of duplicate keys must be
> addressed. In the code shown for insert(), and in the Workshop applet,
> a node with a duplicate key will be inserted as the right child of its
> twin.
>
> The problem is that the find() routine will find only the first of two
> (or more) dupli- cate nodes. The find() routine could be modified to
> check an additional data item, to distinguish data items even when the
> keys were the same, but this would be (at least somewhat)
> time-consuming.
>
> The Complete tree.java Program 405
>
> One option is to simply forbid duplicate keys. When duplicate keys are
> excluded by the nature of the data (employee ID numbers, for example),
> there's no problem.
>
> Otherwise, you need to modify the insert() routine to check for
> equality during the insertion process, and abort the insertion if a
> duplicate is found.
>
> The Fill routine in the Workshop applet excludes duplicates when
> generating the random keys.
>
> **The Complete** tree.java **Program**
>
> In this section we'll show the complete program that includes all the
> methods and code fragments we've looked at so far in this chapter. It
> also features a primitive user interface. This allows the user to
> choose an operation (finding, inserting, deleting, traversing, and
> displaying the tree) by entering characters. The display routine uses
> character output to generate a picture of the tree. Figure 8.22 shows
> the display generated by the program.

![](media/image184.png){width="3.6543088363954506in"
height="2.6533333333333333in"}

> ***FIGURE 8.22*** Output of the tree.java program.
>
> In the figure, the user has typed s to display the tree, then typed i
> and 48 to insert a node with that value, and then s again to display
> the tree with the additional node. The 48 appears in the lower
> display.
>
> The available commands are the characters s, i, f, d, and t, for show,
> insert, find, delete, and traverse. The i, f, and d options ask for
> the key value of the node to be operated on. The t option gives you a
> choice of traversals: 1 for preorder, 2 for inorder, and 3 for
> postorder. The key values are then displayed in that order.
>
> 406 **CHAPTER 8** Binary Trees
>
> The display shows the key values arranged in something of a tree
> shape; however, you'll need to imagine the edges. Two dashes (---)
> represent a node that doesn't exist at a particular position in the
> tree. The program initially creates some nodes so the user will have
> something to see before any insertions are made. You can modify this
> initialization code to start with any nodes you want, or with no nodes
> (which is good nodes).
>
> You can experiment with the program in Listing 8.1 as you can with the
> Workshop applet. Unlike the Workshop applet, however, it doesn't show
> you the steps involved in carrying out an operation; it does
> everything at once.
>
> ***LISTING 8.1*** The tree.java Program
>
> // tree.java
>
> // demonstrates binary tree
>
> // to run this program: C\>java TreeApp import java.io.\*;
>
> import java.util.\*; // for Stack class
>
> //////////////////////////////////////////////////////////////// class
> Node
>
> {
>
> public int iData; // data item (key)
>
> public double dData; // data item
>
> public Node leftChild; // this node's left child public Node
> rightChild; // this node's right child
>
> public void displayNode() // display ourself
>
> {
>
> System.out.print('{');
>
> System.out.print(iData);
>
> System.out.print(", ");
>
> System.out.print(dData);
>
> System.out.print("} ");
>
> }
>
> } // end class Node
>
> //////////////////////////////////////////////////////////////// class
> Tree
>
> {
>
> private Node root; // first node of tree
>
> //
> \-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\--
>
> public Tree() // constructor
>
> { root = null; } // no nodes in tree yet
>
> The Complete tree.java Program 407
>
> ***LISTING 8.1*** Continued
>
> //
> \-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\--
>
> public Node find(int key) // find node with given key
>
> { // (assumes non-empty tree) Node current = root; // start at root
> while(current.iData != key) // while no match,
>
> {
>
> if(key \< current.iData) // go left? current = current.leftChild;
>
> else // or go right?
>
> current = current.rightChild;
>
> if(current == null) // if no child, return null; // didn't find it
>
> }
>
> return current; // found it
>
> } // end find()

//
\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\--

public void insert(int id, double dd)

> {
>
> Node newNode = new Node(); // make new node newNode.iData = id; //
> insert data newNode.dData = dd;
>
> if(root==null) // no node in root root = newNode;
>
> else // root occupied
>
> {
>
> Node current = root; // start at root Node parent;
>
> while(true) // (exits internally)
>
> {
>
> parent = current;
>
> if(id \< current.iData) // go left?
>
> {
>
> current = current.leftChild;
>
> if(current == null) // if end of the line,
>
> { // insert on left parent.leftChild = newNode;
>
> return;
>
> }
>
> } // end if go left
>
> else // or go right?
>
> {
>
> 408 **CHAPTER 8** Binary Trees
>
> ***LISTING 8.1*** Continued
>
> current = current.rightChild;
>
> if(current == null) // if end of the line
>
> { // insert on right parent.rightChild = newNode;

return;

}

> } // end else go right
>
> } // end while
>
> } // end else not root
>
> } // end insert()

//
\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\--

public boolean delete(int key) // delete node with given key

> { // (assumes non-empty list) Node current = root;
>
> Node parent = root;
>
> boolean isLeftChild = true;
>
> while(current.iData != key) // search for node
>
> {
>
> parent = current;
>
> if(key \< current.iData) // go left?
>
> {
>
> isLeftChild = true;
>
> current = current.leftChild;
>
> }
>
> else // or go right?
>
> {
>
> isLeftChild = false;
>
> current = current.rightChild;
>
> }
>
> if(current == null) // end of the line, return false; // didn't find
> it
>
> } // end while
>
> // found node to delete
>
> // if no children, simply delete it if(current.leftChild==null &&
>
> current.rightChild==null)
>
> {
>
> if(current == root) // if root, root = null; // tree is empty
>
> The Complete tree.java Program 409
>
> ***LISTING 8.1*** Continued
>
> else if(isLeftChild)
>
> parent.leftChild = null; // disconnect else // from parent
>
> parent.rightChild = null;
>
> }
>
> // if no right child, replace with left subtree else
> if(current.rightChild==null)
>
> if(current == root)
>
> root = current.leftChild; else if(isLeftChild)
>
> parent.leftChild = current.leftChild; else
>
> parent.rightChild = current.leftChild;
>
> // if no left child, replace with right subtree else
> if(current.leftChild==null)
>
> if(current == root)
>
> root = current.rightChild; else if(isLeftChild)
>
> parent.leftChild = current.rightChild; else
>
> parent.rightChild = current.rightChild;
>
> else // two children, so replace with inorder successor
>
> {
>
> // get successor of node to delete (current) Node successor =
> getSuccessor(current);
>
> // connect parent of current to successor instead if(current == root)
>
> root = successor; else if(isLeftChild)
>
> parent.leftChild = successor; else
>
> parent.rightChild = successor;
>
> // connect successor to current's left child successor.leftChild =
> current.leftChild;
>
> } // end else two children
>
> // (successor cannot have a left child)
>
> 410 **CHAPTER 8** Binary Trees
>
> ***LISTING 8.1*** Continued
>
> return true; // success
>
> } // end delete()
>
> //
> \-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\--
>
> // returns node with next-highest value after delNode
>
> // goes to right child, then right child's left descendents private
> Node getSuccessor(Node delNode)
>
> {
>
> Node successorParent = delNode; Node successor = delNode;
>
> Node current = delNode.rightChild; // go to right child while(current
> != null) // until no more
>
> { // left children,
>
> successorParent = successor; successor = current;
>
> current = current.leftChild; // go to left child
>
> }
>
> // if successor not if(successor != delNode.rightChild) // right
> child,
>
> { // make connections
>
> successorParent.leftChild = successor.rightChild; successor.rightChild
> = delNode.rightChild;
>
> }
>
> return successor;
>
> }
>
> //
> \-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\--
>
> public void traverse(int traverseType)
>
> {
>
> switch(traverseType)
>
> {
>
> case 1: System.out.print("\\nPreorder traversal: "); preOrder(root);
>
> break;
>
> case 2: System.out.print("\\nInorder traversal: "); inOrder(root);
>
> break;
>
> case 3: System.out.print("\\nPostorder traversal: "); postOrder(root);
>
> break;
>
> }
>
> System.out.println();
>
> }
>
> The Complete tree.java Program 411
>
> ***LISTING 8.1*** Continued
>
> //
> \-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\--
>
> private void preOrder(Node localRoot)
>
> {
>
> if(localRoot != null)
>
> {
>
> System.out.print(localRoot.iData + " ");
> preOrder(localRoot.leftChild); preOrder(localRoot.rightChild);
>
> }
>
> }
>
> //
> \-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\--
>
> private void inOrder(Node localRoot)
>
> {
>
> if(localRoot != null)
>
> {
>
> inOrder(localRoot.leftChild); System.out.print(localRoot.iData + " ");
> inOrder(localRoot.rightChild);
>
> }
>
> }
>
> //
> \-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\--
>
> private void postOrder(Node localRoot)
>
> {
>
> if(localRoot != null)
>
> {
>
> postOrder(localRoot.leftChild); postOrder(localRoot.rightChild);
> System.out.print(localRoot.iData + " ");
>
> }
>
> }
>
> //
> \-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\--

public void displayTree()

> {
>
> Stack globalStack = new Stack(); globalStack.push(root);
>
> int nBlanks = 32;
>
> boolean isRowEmpty = false; System.out.println(
>
> "\...\...\...\...\...\...\...\...\...\...\...\...\...\...\...\...\...\...");
>
> while(isRowEmpty==false)
>
> {
>
> 412 **CHAPTER 8** Binary Trees
>
> ***LISTING 8.1*** Continued
>
> Stack localStack = new Stack(); isRowEmpty = true;
>
> for(int j=0; j\<nBlanks; j++) System.out.print(' ');
>
> while(globalStack.isEmpty()==false)
>
> {
>
> Node temp = (Node)globalStack.pop(); if(temp != null)
>
> {
>
> System.out.print(temp.iData); localStack.push(temp.leftChild);
> localStack.push(temp.rightChild);
>
> if(temp.leftChild != null \|\|
>
> temp.rightChild != null) isRowEmpty = false;
>
> }
>
> else
>
> {
>
> System.out.print("\--"); localStack.push(null); localStack.push(null);
>
> }
>
> for(int j=0; j\<nBlanks\*2-2; j++) System.out.print(' ');
>
> } // end while globalStack not empty System.out.println();
>
> nBlanks /= 2; while(localStack.isEmpty()==false)
>
> globalStack.push( localStack.pop() );
>
> } // end while isRowEmpty is false System.out.println(
>
> "\...\...\...\...\...\...\...\...\...\...\...\...\...\...\...\...\...\...");
>
> } // end displayTree()
>
> //
> \-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\--
>
> } // end class Tree
>
> //////////////////////////////////////////////////////////////// class
> TreeApp
>
> {
>
> The Complete tree.java Program 413

***LISTING 8.1*** Continued

> public static void main(String\[\] args) throws IOException
>
> {
>
> int value;
>
> Tree theTree = new Tree();
>
> theTree.insert(50, 1.5);
>
> theTree.insert(25, 1.2);
>
> theTree.insert(75, 1.7);
>
> theTree.insert(12, 1.5);
>
> theTree.insert(37, 1.2);
>
> theTree.insert(43, 1.7);
>
> theTree.insert(30, 1.5);
>
> theTree.insert(33, 1.2);
>
> theTree.insert(87, 1.7);
>
> theTree.insert(93, 1.5);
>
> theTree.insert(97, 1.5);
>
> while(true)
>
> {
>
> System.out.print("Enter first letter of show, ");
> System.out.print("insert, find, delete, or traverse: "); int choice =
> getChar();
>
> switch(choice)
>
> {
>
> case 's':
>
> theTree.displayTree(); break;
>
> case 'i':
>
> System.out.print("Enter value to insert: "); value = getInt();
>
> theTree.insert(value, value + 0.9); break;
>
> case 'f':
>
> System.out.print("Enter value to find: "); value = getInt();
>
> Node found = theTree.find(value); if(found != null)
>
> {
>
> System.out.print("Found: "); found.displayNode();
> System.out.print("\\n");
>
> 414 **CHAPTER 8** Binary Trees
>
> ***LISTING 8.1*** Continued
>
> }
>
> else
>
> System.out.print("Could not find "); System.out.print(value + '\\n');
>
> break; case 'd':
>
> System.out.print("Enter value to delete: "); value = getInt();
>
> boolean didDelete = theTree.delete(value); if(didDelete)
>
> System.out.print("Deleted " + value + '\\n'); else
>
> System.out.print("Could not delete "); System.out.print(value +
> '\\n');
>
> break; case 't':
>
> System.out.print("Enter type 1, 2 or 3: "); value = getInt();
>
> theTree.traverse(value); break;

default:

> System.out.print("Invalid entry\\n");
>
> } // end switch

} // end while

> } // end main()
>
> //
> \-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\--
>
> public static String getString() throws IOException
>
> {
>
> InputStreamReader isr = new InputStreamReader(System.in);
> BufferedReader br = new BufferedReader(isr);
>
> String s = br.readLine(); return s;
>
> }
>
> //
> \-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\--
>
> public static char getChar() throws IOException
>
> {
>
> String s = getString(); return s.charAt(0);
>
> }
>
> //\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\--
>
> public static int getInt() throws IOException

The Huffman Code 415

> ***LISTING 8.1*** Continued
>
> {
>
> String s = getString(); return Integer.parseInt(s);
>
> }
>
> //
> \-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\--
>
> } // end class TreeApp
>
> ////////////////////////////////////////////////////////////////
>
> You can use the ç+C key combination to exit from this program; in the
> interest of simplicity there's no single-letter key for this action.

#### The Huffman Code

> You shouldn't get the idea that binary trees are always search trees.
> Many binary trees are used in other ways. We saw an example in Figure
> 8.11, where a binary tree represents an algebraic expression.
>
> In this section we'll discuss an algorithm that uses a binary tree in
> a surprising way to compress data. It's called the Huffman code, after
> David Huffman who discovered it in 1952. Data compression is important
> in many situations. An example is sending data over the Internet,
> where, especially over a dial-up connection, transmission can take a
> long time. An implementation of this scheme is somewhat lengthy, so we
> won't show a complete program. Instead, we'll focus on the concepts
> and leave the implementation as an exercise.

##### Character Codes

> Each character in a normal uncompressed text file is represented in
> the computer by one byte (for the venerable ASCII code) or by two
> bytes (for the newer Unicode, which is designed to work for all
> languages.) In these schemes, every character requires the same number
> of bits. Table 8.3 shows how some characters are repre- sented in
> binary using the ASCII code. As you can see, every character takes 8
> bits.

+-----------------+--------------------+--------------+
| ***TABLE 8.3*** | > Some ASCII Codes |              |
+=================+====================+==============+
| **Character**   | > **Decimal**      | > **Binary** |
+-----------------+--------------------+--------------+
| A               | > 65               | > 01000000   |
+-----------------+--------------------+--------------+
| B               | > 66               | > 01000001   |
+-----------------+--------------------+--------------+
| C               | > 67               | > 01000010   |
+-----------------+--------------------+--------------+
| ...             | > ...              | > ...        |
+-----------------+--------------------+--------------+
| X               | > 88               | > 01011000   |
+-----------------+--------------------+--------------+
| Y               | > 89               | > 01011001   |
+-----------------+--------------------+--------------+
| Z               | > 90               | > 01011010   |
+-----------------+--------------------+--------------+

> 416 **CHAPTER 8** Binary Trees
>
> There are several approaches to compressing data. For text, the most
> common approach is to reduce the number of bits that represent the
> most-used characters. In English, E is often the most common letter,
> so it seems reasonable to use as few bits as possible to encode it. On
> the other hand, Z is seldom used, so using a large number of bits is
> not so bad.
>
> Suppose we use just two bits for E, say 01. We can't encode every
> letter of the alpha- bet in two bits because there are only four 2-bit
> combinations: 00, 01, 10, and 11.
>
> Can we use these four combinations for the four most-used characters?
> Unfortunately not. We must be careful that no character is represented
> by the same bit combination that appears at the beginning of a longer
> code used for some other character. For example, if E is 01, and X is
> 01011000, then anyone decoding 01011000 wouldn't know if the initial
> 01 represented an E or the beginning of an X. This leads to a rule:
> *No code can be the prefix of any other code*.
>
> Something else to consider is that in some messages E might not be the
> most-used character. If the text is a Java source file, for example,
> the ; (semicolon) character might appear more often than E. Here's the
> solution to that problem: For each message, we make up a new code
> tailored to that particular message. Suppose we want to send the
> message SUSIE SAYS IT IS EASY. The letter S appears a lot, and so does
> the space character. We might want to make up a table showing how many
> times each letter appears. This is called a frequency table, as shown
> in Table 8.4.

+-----------------+-----------------+
| ***TABLE 8.4*** | Frequency Table |
+=================+=================+
| **Character**   | **Count**       |
+-----------------+-----------------+
| A               | > 2             |
+-----------------+-----------------+
| E               | > 2             |
+-----------------+-----------------+
| I               | > 3             |
+-----------------+-----------------+
| S               | > 6             |
+-----------------+-----------------+
| T               | > 1             |
+-----------------+-----------------+
| U               | > 1             |
+-----------------+-----------------+
| Y               | > 2             |
+-----------------+-----------------+
| Space           | > 4             |
+-----------------+-----------------+
| Linefeed        | > 1             |
+-----------------+-----------------+

> The characters with the highest counts should be coded with a small
> number of bits. Table 8.5 shows how we might encode the characters in
> the Susie message.
>
> ***TABLE 8.5*** Huffman Code
>
> **Character Code**
>
> A 010
>
> E 1111
>
> I 110

The Huffman Code 417

+-----------------+-------------+------------+
| ***TABLE 8.5*** | > Continued |            |
+=================+=============+============+
| **Character**   |             | > **Code** |
+-----------------+-------------+------------+
| > S             |             | > 10       |
+-----------------+-------------+------------+
| > T             |             | > 0110     |
+-----------------+-------------+------------+
| > U             |             | > 01111    |
+-----------------+-------------+------------+
| > Y             |             | > 1110     |
+-----------------+-------------+------------+
| > Space         |             | > 00       |
+-----------------+-------------+------------+
| > Linefeed      |             | > 01110    |
+-----------------+-------------+------------+

> We use 10 for S and 00 for the space. We can't use 01 or 11 because
> they are prefixes for other characters. What about 3-bit combinations?
> There are eight possibilities: 000, 001, 010, 011, 100, 101, 110, and
> 111. A is 010 and I is 110. Why aren't any other combinations used? We
> already know we can't use anything starting with 10 or 00; that
> eliminates four possibilities. Also, 011 is used at the beginning of U
> and the linefeed, and 111 is used at the beginning of E and Y. Only
> two 3-bit codes remain, which we use for A and I. In a similar way we
> can see why only three 4-bit codes are available.
>
> Thus, the entire message is coded as
>
> 10 01111 10 110 1111 00 10 010 1110 10 00 110 0110 00 110 10 00
>
> ➥ 1111 010 10 1110 01110
>
> For sanity reasons we show this message broken into the codes for
> individual charac- ters. Of course, in reality all the bits would run
> together; there is no space character in a binary message, only 0s and
> 1s.

##### Decoding with the Huffman Tree

> We'll see later how to create Huffman codes. First, we'll examine the
> somewhat easier process of decoding. Suppose we received the string of
> bits shown in the preceding section. How would we transform it back
> into characters? We can use a kind of binary tree called a *Huffman
> tree*. Figure 8.23 shows the Huffman tree for the code just discussed.
>
> The characters in the message appear in the tree as leaf nodes. The
> higher their frequency in the message, the higher up they appear in
> the tree. The number outside each circle is the frequency. The numbers
> outside non-leaf nodes are the sums of the frequencies of their
> children. We'll see later why this is important.
>
> How do we use this tree to decode the message? For each character you
> start at the root. If you see a 0 bit, you go left to the next node,
> and if you see a 1 bit, you go right. Try it with the code for A,
> which is 010. You go left, then right, then left again, and, *mirabile
> dictu*, you find yourself on the A node. This is shown by the arrows
> in Figure 8.23.
>
> 418 **CHAPTER 8** Binary Trees
>
> ![](media/image185.png)22

2

> ***FIGURE 8.23*** Huffman tree.
>
> You'll see you can do the same with the other characters. If you have
> the patience, you can decode the entire bit string this way.

##### Creating the Huffman Tree

> We've seen how to use the Huffman tree for decoding, but how do we
> create this tree? There are many ways to handle this problem. We'll
> base our approach on the Node and Tree classes in the tree.java
> program in Listing 8.1 (although routines that are specific to search
> trees, like find(), insert(), and delete() are no longer relevant).
> Here is the algorithm for constructing the tree:

1.  Make a Node object (as seen in tree.java) for each character used in
    the message. For our Susie example that would be nine nodes. Each
    node has two data items: the character and that character's
    frequency in the message. Table

> 8.4 provides this information for the Susie message.

2.  Make a tree object for each of these nodes. The node becomes the
    root of the tree.

3.  Insert these trees in a priority queue (as described in Chapter 4).
    They are ordered by frequency, with the smallest frequency having
    the highest priority. That is, when you remove a tree, it's always
    the one with the least-used character.

The Huffman Code 419

> Now do the following:

1.  Remove two trees from the priority queue, and make them into
    children of a new node. The new node has a frequency that is the sum
    of the children's frequencies; its character field can be left
    blank.

2.  Insert this new three-node tree back into the priority queue.

3.  Keep repeating steps 1 and 2. The trees will get larger and larger,
    and there will be fewer and fewer of them. When there is only one
    tree left in the queue, it is the Huffman tree and you're done.

> Figures 8.24 and 8.25 show how the Huffman tree is constructed for the
> Susie message.

![](media/image199.png)![](media/image199.png)![](media/image199.png)![](media/image199.png)![](media/image200.png)1
1 1 2

> ![](media/image201.png)![](media/image201.png)![](media/image201.png)a)
>
> 2 2 3 4 6

![](media/image202.png)![](media/image203.png)![](media/image203.png)![](media/image203.png)![](media/image204.png)![](media/image205.png)![](media/image205.png)![](media/image205.png)![](media/image206.png)1
2 2 2

> ![](media/image203.png)b)
>
> 2 3 4 6

![](media/image207.png)![](media/image199.png)![](media/image199.png)![](media/image203.png)2
2 2 3

> c)
>
> 3 4 6

![](media/image209.png)![](media/image215.png)2 3 3 4 4 6

> d)

3 4 4 5 6

> ![](media/image211.png)e)
>
> ***FIGURE 8.24*** Growing the Huffman tree, Part 1.
>
> 420 **CHAPTER 8** Binary Trees

![](media/image191.png)4 5 6 7

> f)

6 7 9

> ![](media/image225.png)![](media/image229.png)g)

9 13

> ![](media/image232.png)h)
>
> ***FIGURE 8.25*** Growing the Huffman tree, Part 2.

##### Coding the Message

> Now that we have the Huffman tree, how do we code a message? We start
> by creat- ing a code table, which lists the Huffman code alongside
> each character. To simplify the discussion, let's assume that, instead
> of the ASCII code, our computer uses a simplified alphabet that has
> only uppercase letters with 28 characters. A is 0, B is 1, and so on
> up to Z, which is 25. A space is 26, and a linefeed is 27. We number
> these characters so their numerical codes run from 0 to 27. (This is
> not a compressed code, just a simplification of the ASCII code, the
> normal way characters are stored in the computer.)
>
> Our code table would be an array of 28 cells. The index of each cell
> would be the numerical value of the character: 0 for A, 1 for B, and
> so on. The contents of the cell would be the Huffman code for the
> corresponding character. Not every cell contains

The Huffman Code 421

> a code; only those that appear in the message. Figure 8.26 shows how
> this looks for the Susie message.
>
> 0 A

1

2

3

> 4 E
>
> 8 I

18. S

19. T

20. U

> 24 Y
>
> 25

26. space

27. linefeed

> ***FIGURE 8.26*** Code table.
>
> Such a code table makes it easy to generate the coded message: For
> each character in the original message, we use its code as an index
> into the code table. We then repeat- edly append the Huffman codes to
> the end of the coded message until it's complete.

##### Creating the Huffman Code

> How do we create the Huffman code to put into the code table? The
> process is like decoding a message. We start at the root of the
> Huffman tree and follow every possi- ble path to a leaf node. As we go
> along the path, we remember the sequence of left and right choices,
> recording a 0 for a left edge and a 1 for a right edge. When we arrive
> at the leaf node for a character, the sequence of 0s and 1s is the
> Huffman code for that character. We put this code into the code table
> at the appropriate index number.
>
> This process can be handled by calling a method that starts at the
> root and then calls itself recursively for each child. Eventually, the
> paths to all the leaf nodes will be explored and the code table will
> be complete.
>
> 422 **CHAPTER 8** Binary Trees

#### Summary

-   Trees consist of nodes (circles) connected by edges (lines).

-   The root is the topmost node in a tree; it has no parent.

-   In a binary tree, a node has at most two children.

-   In a binary search tree, all the nodes that are left descendants of
    node A have key values less than A; all the nodes that are A's right
    descendants have key values greater than (or equal to) A.

-   Trees perform searches, insertions, and deletions in O(log N) time.

-   Nodes represent the data objects being stored in the tree.

-   Edges are most commonly represented in a program by references to a
    node's children (and sometimes to its parent).

-   Traversing a tree means visiting all its nodes in some order.

-   The simplest traversals are preorder, inorder, and postorder.

-   An unbalanced tree is one whose root has many more left descendents
    than right descendants, or vice versa.

-   Searching for a node involves comparing the value to be found with
    the key value of a node, and going to that node's left child if the
    key search value is less, or to the node's right child if the search
    value is greater.

-   Insertion involves finding the place to insert the new node and then
    changing a child field in its new parent to refer to it.

-   An inorder traversal visits nodes in order of ascending keys.

-   Preorder and postorder traversals are useful for parsing algebraic
    expressions.

-   When a node has no children, it can be deleted by setting the child
    field in its parent to null.

-   When a node has one child, it can be deleted by setting the child
    field in its parent to point to its child.

-   When a node has two children, it can be deleted by replacing it with
    its successor.

-   The successor to a node A can be found by finding the minimum node
    in the subtree whose root is A's right child.

-   In a deletion of a node with two children, different situations
    arise, depending on whether the successor is the right child of the
    node to be deleted or one of the right child's left descendants.

Questions 423

-   Nodes with duplicate key values may cause trouble in arrays because
    only the first one can be found in a search.

-   Trees can be represented in the computer's memory as an array,
    although the reference-based approach is more common.

-   A Huffman tree is a binary tree (but not a search tree) used in a
    data-compres- sion algorithm called Huffman Coding.

-   In the Huffman code the characters that appear most frequently are
    coded with the fewest bits, and those that appear rarely are coded
    with the most bits.

#### Questions

> These questions are intended as a self-test for readers. Answers may
> be found in Appendix C.

1.  Insertion and deletion in a tree require what big O time?

2.  A binary tree is a search tree if

    a.  every non-leaf node has children whose key values are less than
        (or equal to) the parent.

    b.  every left child has a key less than the parent and every right
        child has a key greater than (or equal to) the parent.

    c.  in the path from the root to every leaf node, the key of each
        node is greater than (or equal to) the key of its parent.

    d.  a node can have a maximum of two children.

3.  True or False: Not all trees are binary trees.

4.  In a complete binary tree with 20 nodes, and the root considered to
    be at level 0, how many nodes are there at level 4?

5.  A subtree of a binary tree always has

    e.  a root that is a child of the main tree's root.

    f.  a root unconnected to the main tree's root.

    g.  fewer nodes than the main tree.

    h.  a sibling with the same number of nodes.

6.  In the Java code for a tree, the [ ]{.underline} and the [
    ]{.underline} are generally separate classes.

> 424 **CHAPTER 8** Binary Trees

7.  Finding a node in a binary search tree involves going from node to
    node, asking

    i.  how big the node's key is in relation to the search key.

    j.  how big the node's key is compared to its right or left
        children.

    k.  what leaf node we want to reach.

    l.  what level we are on.

8.  An unbalanced tree is one

    m.  in which most of the keys have values greater than the average.

    n.  whose behavior is unpredictable.

    o.  in which the root or some other node has many more left children
        than right children, or vice versa.

    p.  that is shaped like an umbrella.

9.  Inserting a node starts with the same steps as [ ]{.underline} a
    node.

10. Suppose a node A has a successor node S. Then S must have a key that
    is larger than [ ]{.underline} but smaller than or equal to [
    ]{.underline} .

11. In a binary tree used to represent a mathematical expression, which
    of the following is not true?

    q.  Both children of an operator node must be operands.

    r.  Following a postorder traversal, no parentheses need to be
        added.

    s.  Following an inorder traversal, parentheses must be added.

    t.  In pre-order traversal a node is visited before either of its
        children.

12. If a tree is represented by an array, the right child of a node at
    index n has an index of [ ]{.underline} .

13. True or False: Deleting a node with one child from a binary search
    tree involves finding that node's successor.

14. A Huffman tree is typically used to [ ]{.underline} text.

15. Which of the following is not true about a Huffman tree?

    u.  The most frequently used characters always appear near the top
        of the tree.

    v.  Normally, decoding a message involves repeatedly following a
        path from the root to a leaf.

Programming Projects 425

w.  In coding a character you typically start at a leaf and work upward.

x.  The tree can be generated by removal and insertion operations on a
    priority queue.

#### Experiments

> Carrying out these experiments will help to provide insights into the
> topics covered in the chapter. No programming is involved.

1.  Use the Binary Tree Workshop applet to create 20 trees. What
    percentage would you say are seriously unbalanced?

2.  Create a UML activity diagram (or flowchart, for you old-timers) of
    the various possibilities when deleting a node from a binary search
    tree. It should detail the three cases described in the text.
    Include the variations for left and right children and special cases
    like deletion of the root. For example, there are two possibilities
    for case 1 (left and right children). Boxes at the end of each path
    should describe how to do the deletion in that situation.

3.  Use the Binary Tree Workshop applet to delete a node in every
    possible situation.

#### Programming Projects

> Writing programs to solve the Programming Projects helps to solidify
> your under- standing of the material and demonstrates how the
> chapter's concepts are applied. (As noted in the Introduction,
> qualified instructors may obtain completed solutions to the
> Programming Projects on the publisher's Web site.)

1.  Start with the tree.java program (Listing 8.1) and modify it to
    create a binary tree from a string of letters (like A, B, and so on)
    entered by the user. Each letter will be displayed in its own node.
    Construct the tree so that all the nodes that contain letters are
    leaves. Parent nodes can contain some non-letter symbol like +. Make
    sure that every parent node has exactly two children. Don't worry if
    the tree is unbalanced. Note that this will not be a search tree;
    there's no quick way to find a given node. You may end up with
    something like this:

\+

> \+ E
>
> \+ D - -
>
> \+ C - - - - - - A B - - - - - - - - - - - - - -
>
> 426 **CHAPTER 8** Binary Trees
>
> One way to begin is by making an array of trees. (A group of
> unconnected trees is called a *forest*.) Take each letter typed by the
> user and put it in a node. Take each of these nodes and put it in a
> tree, where it will be the root. Now put all these one-node trees in
> the array. Start by making a new tree with + at the root and two of
> the one-node trees as its children. Then keep adding one-node trees
> from the array to this larger tree. Don't worry if it's an unbalanced
> tree. You can actually store this intermediate tree in the array by
> writing over a cell whose contents have already been added to the
> tree.
>
> The routines find(), insert(), and delete(), which apply only to
> search trees, can be deleted. Keep the displayTree() method and the
> traversals because they will work on any binary tree.

2.  Expand the program in Programming Project 8.1 to create a balanced
    tree. One way to do this is to make sure that as many leaves as
    possible appear in the bottom row. You can start by making a
    three-node tree out of each pair of one- node trees, making a new +
    node for the root. This results in a forest of three- node trees.
    Then combine each pair of three-node trees to make a forest of
    seven-node trees. As the number of nodes per tree grows, the number
    of trees shrinks, until finally there is only one tree left.

    Again, start with the tree.java program and make a tree from
    characters typed by the user. This time, make a complete tree---one
    that is completely full except possibly on the right end of the
    bottom row. The characters should be ordered from the top down and
    from left to right along each row, as if writing a letter on a
    pyramid. (This arrangement does not correspond to any of the three
    traversals we discussed in this chapter.) Thus, the string
    ABCDEFGHIJ would be arranged as

A

B C

D E F G

> H I J
>
> One way to create this tree is from the top down, rather than the
> bottom up as in the previous two Programming Projects. Start by
> creating a node which will be the root of the final tree. If you think
> of the nodes as being numbered in the same order the letters are
> arranged, with 1 at the root, then any node numbered n has a left
> child numbered 2\*n and a right child numbered 2\*n+1.
>
> You might use a recursive routine that makes two children and then
> calls itself for each child. The nodes don't need to be created in the
> same order they are arranged on the tree. As in the previous
> Programming Projects, you can jettison the search-tree routines from
> the Tree class.

Programming Projects 427

4.  Write a program that transforms a postfix expression into a tree
    such as that shown in Figure 8.11 in this chapter. You'll need to
    modify the Tree class from the tree.java program (Listing 8.1) and
    the ParsePost class from the postfix.java program (Listing 4.8) in
    Chapter 4. There are more details in the discussion of Figure 8.11.

> After the tree is generated, traversals of the tree will yield the
> prefix, infix, and postfix equivalents of the algebraic expression.
> The infix version will need parentheses to avoid generating ambiguous
> expressions. In the inOrder() method, display an opening parenthesis
> before the first recursive call and a closing parenthesis after the
> second recursive call.

5.  Write a program to implement Huffman coding and decoding. It should
    do the following:

> Accept a text message, possibly of more than one line. Create a
> Huffman tree for this message.
>
> Create a code table.
>
> Encode the message into binary.
>
> Decode the message from binary back to text.
>
> If the message is short, the program should be able to display the
> Huffman tree after creating it. The ideas in Programming Projects 8.1,
> 8.2, and 8.3 might prove helpful. You can use String variables to
> store binary numbers as arrange- ments of the characters 1 and 0.
> Don't worry about doing actual bit manipula- tion unless you really
> want to.
